{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting award names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715\n",
      "395\n",
      "148\n",
      "105\n",
      "87\n",
      "56\n",
      "39\n",
      "36\n",
      "Best Drama\n",
      "Best Supporting Actor in a Motion Picture\n",
      "Best Supporting Actress for Television\n",
      "Best Miniseries or Television Motion Picture\n",
      "Best Actress in a Miniseries or Television Motion Picture\n",
      "Best Actor Television Drama\n",
      "Best Television Drama\n",
      "Best Original Score in a Motion Picture\n",
      "Best Original Song Motion Picture\n",
      "Best Actor in a Miniseries or Television Film\n",
      "Best Actor in a Television Miniseries\n",
      "Best Actress Comedy or Musical\n",
      "Best Actress in a Motion Picture Comedy or Musical\n",
      "Best Supporting Actor in a Television\n",
      "Best Supporting Actress in a Motion Picture Drama\n",
      "Best Motion Picture Screenplay\n",
      "Best Actor in a Television Comedy or Musical\n",
      "Best Foreign Language Film\n",
      "Best Screenplay Golden Globes\n",
      "Best Actress Television Drama\n",
      "Best Actress in Television\n",
      "Best Actress in a Television Comedy\n",
      "Best Animated Film Golden Globes\n",
      "Best Director Motion Picture\n",
      "Best Television Comedy or Musical\n",
      "Best Comedy\n",
      "Best Actor in Television\n",
      "Best Actor in Motion Picture\n",
      "Best Motion Picture Comedy or Musical\n",
      "Best Supporting Actor Golden Globes\n",
      "Best Actress Drama\n",
      "Best Actress in a Motion Picture Drama\n",
      "Best Actor in a Motion Picture Drama\n",
      "Best Actor in Motion Drama\n",
      "Best Motion Picture Drama\n",
      "Best Director Golden Globes\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import json \n",
    "import os\n",
    "\n",
    "def load_json(filename):\n",
    "    path = os.path.join(os.getcwd(), filename)\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# loading the data\n",
    "data = load_json(\"/Users/gustavolucasdecarvalho/Desktop/CS_337/gg2013.json\")\n",
    "\n",
    "# data without retweets\n",
    "data_no_rt = []\n",
    "for tw in data:\n",
    "    text = tw[\"text\"]\n",
    "\n",
    "    if not re.search(\"^RT\\s\", text):\n",
    "        data_no_rt.append(tw)\n",
    "\n",
    "# getting the tweets that start with \"Best\" and continue on with another word with a capital letter\n",
    "has_best = []\n",
    "for tw in data_no_rt:\n",
    "    text = tw[\"text\"]\n",
    "\n",
    "    if re.search(\"^Best\\s[A-Z].+\", text):\n",
    "        has_best.append(text)\n",
    "\n",
    "awards_d = Counter(has_best)\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "## further filtering idea by grabbing relevant sentence structure\n",
    "a_lst = []\n",
    "for k in awards_d.keys():\n",
    "    goes_to = re.search(\"[gG]oes [Tt]o\",k)\n",
    "    if goes_to:\n",
    "        a_lst.append(k[:goes_to.start()].strip())\n",
    "\n",
    "    colon = re.search(\":\\s\",k)\n",
    "    if colon:\n",
    "        a_lst.append(k[:colon.start()].strip())\n",
    "\n",
    "    dash = re.search(\"^Best\\s[A-Z].+\\s-\",k)\n",
    "    if dash:\n",
    "        a_lst.append(k[:dash.end()-2].strip())\n",
    "\n",
    "awards_d = Counter(a_lst)\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# deleting tweets which fit one of a given set of heuristics that I found to be a good way to filter out tweets\n",
    "del_lst = []\n",
    "for k, v in awards_d.items():\n",
    "    sen = k.split(\" \")\n",
    "    bools = (len(sen) > 9) or re.search(\"[^\\w\\s]\", k) #or (v<2) # or (':' in k) or (',' in k) or ('-' in k)\n",
    "    if bools: del_lst.append(k)\n",
    "for k in del_lst:\n",
    "    del awards_d[k]\n",
    "\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# deleting all tweets that only show up once if they don't have the words present in the tweets that show up more than once\n",
    "words_set = set()\n",
    "for k, v in awards_d.items():\n",
    "    if v > 1: \n",
    "        k = k.split(\" \")\n",
    "        for w in k:\n",
    "            words_set.add(w)\n",
    "\n",
    "del_lst = []\n",
    "for k, v in awards_d.items():\n",
    "    sen = k.split(\" \")\n",
    "    if v == 1:\n",
    "        for w in sen:\n",
    "            if w not in words_set:\n",
    "                del_lst.append(k)\n",
    "                break\n",
    "for k in del_lst:\n",
    "    del awards_d[k]\n",
    "\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# replace words with synonyms to create more explicit duplicates which are then removed\n",
    "new_awards_d = Counter()\n",
    "for k, v in awards_d.items():\n",
    "    k = k.replace(\"TV Series\", \"Television\")\n",
    "    k = k.replace(\"Television Series\", \"Television\")\n",
    "    k = k.replace(\" TV \", \" Television \")\n",
    "    k = k.replace(\" TV\", \" Television\")\n",
    "\n",
    "    k = k.replace(\" Movie \", \" Motion Picture \")\n",
    "    k = k.replace(\" Movie\", \" Motion Picture\")\n",
    "\n",
    "    k = k.replace(\"Mini Series\", \"Miniseries\")\n",
    "    k = k.replace(\"Mini series\", \"Miniseries\")\n",
    "    k = k.replace(\"mini series\", \"Miniseries\")\n",
    "\n",
    "    k = k.replace(\"Foreign Film\", \"Foreign Language Film\")\n",
    "    k = k.replace( \"Feature Film\", \"Film\")\n",
    "\n",
    "    k = k.replace(\"Performance by an\", \"\")\n",
    "    k = k.replace(\"  \", \" \")\n",
    "    \n",
    "    new_awards_d[k] += v\n",
    "\n",
    "awards_d = new_awards_d\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# removing duplicates which only differ by spaces, symbols, or different wording\n",
    "awards_set = Counter()\n",
    "awards_d_to_s = {}\n",
    "for k, v in awards_d.items():\n",
    "    clean_k = k.replace(\"in a\", \"\")\n",
    "    clean_k = clean_k.replace(\"for\", \"\")\n",
    "    clean_k = clean_k.replace(\"Made\", \"\")\n",
    "    clean_k = clean_k.replace(\"or\", \"\")\n",
    "\n",
    "    clean_k = clean_k.replace(\"Feature Film\", \"Picture\")\n",
    "    clean_k = clean_k.replace(\"Feature\", \"Picture\")\n",
    "    clean_k = clean_k.replace(\"Original\", \"\")\n",
    "    clean_k = clean_k.replace(\"Musical\", \"\")\n",
    "    clean_k = clean_k.replace(\"Series\", \"\")\n",
    "    \n",
    "    clean_k = clean_k.replace(\"Motion Picture\", \"Picture\")\n",
    "    clean_k = clean_k.replace(\"Film\", \"Picture\")\n",
    "    clean_k = clean_k.replace(\"Comedy or Musical\", \"Comedy\")\n",
    "    clean_k = clean_k.replace(\" \", \"\")\n",
    "\n",
    "    txt_lst = re.split(\"/W\", clean_k)\n",
    "    txt_lst = [*\" \".join(txt_lst).strip()]\n",
    "    txt_lst.sort()\n",
    "    txt = \"\".join(txt_lst)\n",
    "\n",
    "    awards_d_to_s[k] = txt\n",
    "    awards_set[txt] += v\n",
    "\n",
    "seen = set()\n",
    "new_awards_d = Counter()\n",
    "for k, v in awards_d.items():\n",
    "    txt = awards_d_to_s[k]\n",
    "    if txt not in seen:\n",
    "        seen.add(txt)\n",
    "        new_awards_d[k] = awards_set[txt]\n",
    "\n",
    "awards_d = new_awards_d\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# deleting more duplicates\n",
    "del_set = set()\n",
    "for k in awards_d.keys():\n",
    "    k_lst = k.split(\" \")\n",
    "    for k2 in awards_d.keys():\n",
    "        k2_lst = k2.split(\" \")\n",
    "\n",
    "        if len(k_lst) >= len(k2_lst):\n",
    "            continue\n",
    "        elif k_lst == k2_lst[:len(k_lst)]:\n",
    "            del_set.add(k)\n",
    "for d in del_set:\n",
    "    del awards_d[d]\n",
    "\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# deleting awards that have \"in a\" but no \"Motion Picture / Television / Miniseries\"\n",
    "del_lst = []\n",
    "for k, v in awards_d.items():\n",
    "    if \"in a\" in k:\n",
    "        if not (\"Motion Picture\" in k or \"Television\" in k or \"Miniseries\" in k):\n",
    "            del_lst.append(k)\n",
    "for k in del_lst:\n",
    "    del awards_d[k]\n",
    "\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# printing list of awards\n",
    "awards_lst = list(awards_d.keys())\n",
    "for a in awards_lst:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best dressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden Globes\n"
     ]
    }
   ],
   "source": [
    "has_best = []\n",
    "for tw in data_no_rt:\n",
    "    text = tw[\"text\"]\n",
    "\n",
    "    if re.search(\"beautiful|gorgeous|fabulous|sexy|dashing|handsome|\\shot\\s|impeccable\", text.lower()):\n",
    "        poss_person = re.search(\"[A-Z][a-z]+\\s[A-Z][a-z]+\\s\", text)\n",
    "        if poss_person:\n",
    "            has_best.append(text[poss_person.start():poss_person.end()].strip())\n",
    "\n",
    "g_dress_tw = Counter(has_best)\n",
    "best_dressed = g_dress_tw.most_common()[0][0]\n",
    "print(best_dressed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse Dressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Golden Globes', 5),\n",
       " ('Claire Danes', 3),\n",
       " ('Bill Murray', 2),\n",
       " ('Anne Hathaway', 2),\n",
       " ('Lena Dunham', 2),\n",
       " ('Jodie Foster', 2),\n",
       " ('Lucy Liu', 1),\n",
       " ('Natalie Morales', 1),\n",
       " ('Sofia Vergara', 1),\n",
       " ('Best Supporting', 1),\n",
       " ('Lena Duhnam', 1),\n",
       " ('Tina Fey', 1),\n",
       " ('Most Ridiculous', 1),\n",
       " ('Amy Poehler', 1),\n",
       " ('Damien Lewis', 1),\n",
       " ('Dana Brody', 1),\n",
       " ('Abu Nazir', 1),\n",
       " ('Jennifer Lawrence', 1),\n",
       " ('Best Director', 1),\n",
       " ('God Bless', 1),\n",
       " ('Kristen Wiig', 1),\n",
       " ('Megan Fox', 1),\n",
       " ('Globes Anne', 1),\n",
       " ('Lucy Luis', 1),\n",
       " ('Lucy Lui', 1),\n",
       " ('Lucy Lu', 1),\n",
       " ('Connie Britton', 1),\n",
       " ('Selena Gomez', 1),\n",
       " ('Sienna Miller', 1),\n",
       " ('Sasha Baren', 1),\n",
       " ('Jodi Fosters', 1),\n",
       " ('Red Carpet', 1),\n",
       " ('Halle Berry', 1),\n",
       " ('Berry That', 1),\n",
       " ('Ben Affleck', 1),\n",
       " ('Jodi Foster', 1),\n",
       " ('Jeremy Renner', 1),\n",
       " ('Comedy Golden', 1),\n",
       " ('Helen Mirren', 1),\n",
       " ('Jessica Chastain', 1),\n",
       " ('Hilton The', 1),\n",
       " ('In The', 1),\n",
       " ('Definitely Ben', 1),\n",
       " ('Taylor Swift', 1),\n",
       " ('Benedict Cumberbatch', 1)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_best = []\n",
    "for tw in data_no_rt:\n",
    "    text = tw[\"text\"]\n",
    "\n",
    "    if re.search(\"hideous|ridiculous|ugly|\\sbland\\s|looks.+\\sbad|bad\\s.+looks\", text.lower()):\n",
    "        poss_person = re.search(\"[A-Z][a-z]+\\s[A-Z][a-z]+\\s\", text)\n",
    "        if poss_person:\n",
    "            has_best.append(text[poss_person.start():poss_person.end()].strip())\n",
    "\n",
    "b_dress_tw = Counter(has_best)\n",
    "b_dress_tw.most_common()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
