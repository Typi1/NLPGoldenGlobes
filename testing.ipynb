{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting award names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715\n",
      "395\n",
      "148\n",
      "105\n",
      "87\n",
      "56\n",
      "39\n",
      "36\n",
      "Best Drama\n",
      "Best Supporting Actor in a Motion Picture\n",
      "Best Supporting Actress for Television\n",
      "Best Miniseries or Television Motion Picture\n",
      "Best Actress in a Miniseries or Television Motion Picture\n",
      "Best Actor Television Drama\n",
      "Best Television Drama\n",
      "Best Original Score in a Motion Picture\n",
      "Best Original Song Motion Picture\n",
      "Best Actor in a Miniseries or Television Film\n",
      "Best Actor in a Television Miniseries\n",
      "Best Actress Comedy or Musical\n",
      "Best Actress in a Motion Picture Comedy or Musical\n",
      "Best Supporting Actor in a Television\n",
      "Best Supporting Actress in a Motion Picture Drama\n",
      "Best Motion Picture Screenplay\n",
      "Best Actor in a Television Comedy or Musical\n",
      "Best Foreign Language Film\n",
      "Best Screenplay Golden Globes\n",
      "Best Actress Television Drama\n",
      "Best Actress in Television\n",
      "Best Actress in a Television Comedy\n",
      "Best Animated Film Golden Globes\n",
      "Best Director Motion Picture\n",
      "Best Television Comedy or Musical\n",
      "Best Comedy\n",
      "Best Actor in Television\n",
      "Best Actor in Motion Picture\n",
      "Best Motion Picture Comedy or Musical\n",
      "Best Supporting Actor Golden Globes\n",
      "Best Actress Drama\n",
      "Best Actress in a Motion Picture Drama\n",
      "Best Actor in a Motion Picture Drama\n",
      "Best Actor in Motion Drama\n",
      "Best Motion Picture Drama\n",
      "Best Director Golden Globes\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import json \n",
    "import os\n",
    "\n",
    "def load_json(filename):\n",
    "    path = os.path.join(os.getcwd(), filename)\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# loading the data\n",
    "data = load_json(\"/Users/gustavolucasdecarvalho/Desktop/CS_337/gg2013.json\")\n",
    "\n",
    "# data without retweets\n",
    "data_no_rt = []\n",
    "for tw in data:\n",
    "    text = tw[\"text\"]\n",
    "\n",
    "    if not re.search(\"^RT\\s\", text):\n",
    "        data_no_rt.append(tw)\n",
    "\n",
    "# getting the tweets that start with \"Best\" and continue on with another word with a capital letter\n",
    "has_best = []\n",
    "for tw in data_no_rt:\n",
    "    text = tw[\"text\"]\n",
    "\n",
    "    if re.search(\"^Best\\s[A-Z].+\", text):\n",
    "        has_best.append(text)\n",
    "\n",
    "awards_d = Counter(has_best)\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "## further filtering idea by grabbing relevant sentence structure\n",
    "a_lst = []\n",
    "for k in awards_d.keys():\n",
    "    goes_to = re.search(\"[gG]oes [Tt]o\",k)\n",
    "    if goes_to:\n",
    "        a_lst.append(k[:goes_to.start()].strip())\n",
    "\n",
    "    colon = re.search(\":\\s\",k)\n",
    "    if colon:\n",
    "        a_lst.append(k[:colon.start()].strip())\n",
    "\n",
    "    dash = re.search(\"^Best\\s[A-Z].+\\s-\",k)\n",
    "    if dash:\n",
    "        a_lst.append(k[:dash.end()-2].strip())\n",
    "\n",
    "awards_d = Counter(a_lst)\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# deleting tweets which fit one of a given set of heuristics that I found to be a good way to filter out tweets\n",
    "del_lst = []\n",
    "for k, v in awards_d.items():\n",
    "    sen = k.split(\" \")\n",
    "    bools = (len(sen) > 9) or re.search(\"[^\\w\\s]\", k) #or (v<2) # or (':' in k) or (',' in k) or ('-' in k)\n",
    "    if bools: del_lst.append(k)\n",
    "for k in del_lst:\n",
    "    del awards_d[k]\n",
    "\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# deleting all tweets that only show up once if they don't have the words present in the tweets that show up more than once\n",
    "words_set = set()\n",
    "for k, v in awards_d.items():\n",
    "    if v > 1: \n",
    "        k = k.split(\" \")\n",
    "        for w in k:\n",
    "            words_set.add(w)\n",
    "\n",
    "del_lst = []\n",
    "for k, v in awards_d.items():\n",
    "    sen = k.split(\" \")\n",
    "    if v == 1:\n",
    "        for w in sen:\n",
    "            if w not in words_set:\n",
    "                del_lst.append(k)\n",
    "                break\n",
    "for k in del_lst:\n",
    "    del awards_d[k]\n",
    "\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# replace words with synonyms to create more explicit duplicates which are then removed\n",
    "new_awards_d = Counter()\n",
    "for k, v in awards_d.items():\n",
    "    k = k.replace(\"TV Series\", \"Television\")\n",
    "    k = k.replace(\"Television Series\", \"Television\")\n",
    "    k = k.replace(\" TV \", \" Television \")\n",
    "    k = k.replace(\" TV\", \" Television\")\n",
    "\n",
    "    k = k.replace(\" Movie \", \" Motion Picture \")\n",
    "    k = k.replace(\" Movie\", \" Motion Picture\")\n",
    "\n",
    "    k = k.replace(\"Mini Series\", \"Miniseries\")\n",
    "    k = k.replace(\"Mini series\", \"Miniseries\")\n",
    "    k = k.replace(\"mini series\", \"Miniseries\")\n",
    "\n",
    "    k = k.replace(\"Foreign Film\", \"Foreign Language Film\")\n",
    "    k = k.replace( \"Feature Film\", \"Film\")\n",
    "\n",
    "    k = k.replace(\"Performance by an\", \"\")\n",
    "    k = k.replace(\"  \", \" \")\n",
    "    \n",
    "    new_awards_d[k] += v\n",
    "\n",
    "awards_d = new_awards_d\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# removing duplicates which only differ by spaces, symbols, or different wording\n",
    "awards_set = Counter()\n",
    "awards_d_to_s = {}\n",
    "for k, v in awards_d.items():\n",
    "    clean_k = k.replace(\"in a\", \"\")\n",
    "    clean_k = clean_k.replace(\"for\", \"\")\n",
    "    clean_k = clean_k.replace(\"Made\", \"\")\n",
    "    clean_k = clean_k.replace(\"or\", \"\")\n",
    "\n",
    "    clean_k = clean_k.replace(\"Feature Film\", \"Picture\")\n",
    "    clean_k = clean_k.replace(\"Feature\", \"Picture\")\n",
    "    clean_k = clean_k.replace(\"Original\", \"\")\n",
    "    clean_k = clean_k.replace(\"Musical\", \"\")\n",
    "    clean_k = clean_k.replace(\"Series\", \"\")\n",
    "    \n",
    "    clean_k = clean_k.replace(\"Motion Picture\", \"Picture\")\n",
    "    clean_k = clean_k.replace(\"Film\", \"Picture\")\n",
    "    clean_k = clean_k.replace(\"Comedy or Musical\", \"Comedy\")\n",
    "    clean_k = clean_k.replace(\" \", \"\")\n",
    "\n",
    "    txt_lst = re.split(\"/W\", clean_k)\n",
    "    txt_lst = [*\" \".join(txt_lst).strip()]\n",
    "    txt_lst.sort()\n",
    "    txt = \"\".join(txt_lst)\n",
    "\n",
    "    awards_d_to_s[k] = txt\n",
    "    awards_set[txt] += v\n",
    "\n",
    "seen = set()\n",
    "new_awards_d = Counter()\n",
    "for k, v in awards_d.items():\n",
    "    txt = awards_d_to_s[k]\n",
    "    if txt not in seen:\n",
    "        seen.add(txt)\n",
    "        new_awards_d[k] = awards_set[txt]\n",
    "\n",
    "awards_d = new_awards_d\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# deleting more duplicates\n",
    "del_set = set()\n",
    "for k in awards_d.keys():\n",
    "    k_lst = k.split(\" \")\n",
    "    for k2 in awards_d.keys():\n",
    "        k2_lst = k2.split(\" \")\n",
    "\n",
    "        if len(k_lst) >= len(k2_lst):\n",
    "            continue\n",
    "        elif k_lst == k2_lst[:len(k_lst)]:\n",
    "            del_set.add(k)\n",
    "for d in del_set:\n",
    "    del awards_d[d]\n",
    "\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# deleting awards that have \"in a\" but no \"Motion Picture / Television / Miniseries\"\n",
    "del_lst = []\n",
    "for k, v in awards_d.items():\n",
    "    if \"in a\" in k:\n",
    "        if not (\"Motion Picture\" in k or \"Television\" in k or \"Miniseries\" in k):\n",
    "            del_lst.append(k)\n",
    "for k in del_lst:\n",
    "    del awards_d[k]\n",
    "\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# printing list of awards\n",
    "awards_lst = list(awards_d.keys())\n",
    "for a in awards_lst:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715\n",
      "395\n",
      "42\n",
      "42\n",
      "35\n",
      "34\n",
      "23\n",
      "21\n",
      "Best Drama\n",
      "Best Supporting Actor in a Motion Picture\n",
      "Best Miniseries or Television Motion Picture\n",
      "Best Miniseries or Motion Picture Made for Television\n",
      "Best Actress in a Miniseries or Television Motion Picture\n",
      "Best Actor in a Television\n",
      "Best Television Drama\n",
      "Best Original Score\n",
      "Best Original Song\n",
      "Best Supporting Actress in a Motion Picture\n",
      "Best Screenplay Motion Picture\n",
      "Best Foreign Language Film\n",
      "Best Actress Television Drama\n",
      "Best Actress in a Television Comedy\n",
      "Best Animated Film Golden Globes\n",
      "Best Director\n",
      "Best Motion Picture Comedy or Musical\n",
      "Best Picture\n",
      "Best Actress in a Motion Picture Drama\n",
      "Best Actor in a Motion Picture Drama\n",
      "Best Motion Picture Drama\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import json \n",
    "import os\n",
    "\n",
    "def load_json(filename):\n",
    "    path = os.path.join(os.getcwd(), filename)\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# loading the data\n",
    "data = load_json(\"/Users/gustavolucasdecarvalho/Desktop/CS_337/gg2013.json\")\n",
    "\n",
    "# data without retweets\n",
    "data_no_rt = []\n",
    "for tw in data:\n",
    "    text = tw[\"text\"]\n",
    "\n",
    "    if not re.search(\"^RT\\s\", text):\n",
    "        data_no_rt.append(tw)\n",
    "\n",
    "# getting the tweets that start with \"Best\" and continue on with another word with a capital letter\n",
    "has_best = []\n",
    "for tw in data_no_rt:\n",
    "    text = tw[\"text\"]\n",
    "\n",
    "    if re.search(\"^Best\\s[A-Z].+\", text):\n",
    "        has_best.append(text)\n",
    "\n",
    "awards_d = Counter(has_best)\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "## further filtering idea by grabbing relevant sentence structure\n",
    "a_lst = []\n",
    "for k in awards_d.keys():\n",
    "    goes_to = re.search(\"[gG]oes [Tt]o\",k)\n",
    "    if goes_to:\n",
    "        a_lst.append(k[:goes_to.start()].strip())\n",
    "\n",
    "    colon = re.search(\":\\s\",k)\n",
    "    if colon:\n",
    "        a_lst.append(k[:colon.start()].strip())\n",
    "\n",
    "    dash = re.search(\"^Best\\s[A-Z].+\\s-\",k)\n",
    "    if dash:\n",
    "        a_lst.append(k[:dash.end()-2].strip())\n",
    "\n",
    "awards_d = Counter(a_lst)\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# deleting tweets which fit one of a given set of heuristics that I found to be a good way to filter out tweets\n",
    "del_lst = []\n",
    "for k, v in awards_d.items():\n",
    "    sen = k.split(\" \")\n",
    "    bools = (len(sen) > 9) or re.search(\"[^\\w\\s]\", k) or (v<2) # or (':' in k) or (',' in k) or ('-' in k)\n",
    "    if bools: del_lst.append(k)\n",
    "for k in del_lst:\n",
    "    del awards_d[k]\n",
    "\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# deleting all tweets that only show up once if they don't have the words present in the tweets that show up more than once\n",
    "words_set = set()\n",
    "for k, v in awards_d.items():\n",
    "    if v > 1: \n",
    "        k = k.split(\" \")\n",
    "        for w in k:\n",
    "            words_set.add(w)\n",
    "\n",
    "del_lst = []\n",
    "for k, v in awards_d.items():\n",
    "    sen = k.split(\" \")\n",
    "    if v == 1:\n",
    "        for w in sen:\n",
    "            if w not in words_set:\n",
    "                del_lst.append(k)\n",
    "                break\n",
    "for k in del_lst:\n",
    "    del awards_d[k]\n",
    "\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# replace words with synonyms to create more explicit duplicates which are then removed\n",
    "new_awards_d = Counter()\n",
    "for k, v in awards_d.items():\n",
    "    k = k.replace(\"TV Series\", \"Television\")\n",
    "    k = k.replace(\"Television Series\", \"Television\")\n",
    "    k = k.replace(\" TV \", \" Television \")\n",
    "    k = k.replace(\" TV\", \" Television\")\n",
    "\n",
    "    k = k.replace(\" Movie \", \" Motion Picture \")\n",
    "    k = k.replace(\" Movie\", \" Motion Picture\")\n",
    "\n",
    "    k = k.replace(\"Mini Series\", \"Miniseries\")\n",
    "    k = k.replace(\"Mini series\", \"Miniseries\")\n",
    "    k = k.replace(\"mini series\", \"Miniseries\")\n",
    "\n",
    "    k = k.replace(\"Foreign Film\", \"Foreign Language Film\")\n",
    "    k = k.replace( \"Feature Film\", \"Film\")\n",
    "\n",
    "    k = k.replace(\"Performance by an\", \"\")\n",
    "    k = k.replace(\"  \", \" \")\n",
    "    \n",
    "    new_awards_d[k] += v\n",
    "\n",
    "awards_d = new_awards_d\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# removing duplicates which only differ by spaces, symbols, or different wording\n",
    "awards_set = Counter()\n",
    "awards_d_to_s = {}\n",
    "for k, v in awards_d.items():\n",
    "    # clean_k = k.replace(\"in a\", \"\")\n",
    "    # clean_k = clean_k.replace(\"for\", \"\")\n",
    "    # clean_k = clean_k.replace(\"Made\", \"\")\n",
    "    # clean_k = clean_k.replace(\"or\", \"\")\n",
    "\n",
    "    # clean_k = clean_k.replace(\"Feature Film\", \"Picture\")\n",
    "    # clean_k = clean_k.replace(\"Feature\", \"Picture\")\n",
    "    # clean_k = clean_k.replace(\"Original\", \"\")\n",
    "    # clean_k = clean_k.replace(\"Musical\", \"\")\n",
    "    # clean_k = clean_k.replace(\"Series\", \"\")\n",
    "    \n",
    "    # clean_k = clean_k.replace(\"Motion Picture\", \"Picture\")\n",
    "    # clean_k = clean_k.replace(\"Film\", \"Picture\")\n",
    "    # clean_k = clean_k.replace(\"Comedy or Musical\", \"Comedy\")\n",
    "    # clean_k = clean_k.replace(\" \", \"\")\n",
    "\n",
    "    txt_lst = re.split(\"/W\", k)\n",
    "    txt_lst = [*\" \".join(txt_lst).strip()]\n",
    "    txt_lst.sort()\n",
    "    txt = \"\".join(txt_lst)\n",
    "\n",
    "    awards_d_to_s[k] = txt\n",
    "    awards_set[txt] += v\n",
    "\n",
    "seen = set()\n",
    "new_awards_d = Counter()\n",
    "for k, v in awards_d.items():\n",
    "    txt = awards_d_to_s[k]\n",
    "    if txt not in seen:\n",
    "        seen.add(txt)\n",
    "        new_awards_d[k] = awards_set[txt]\n",
    "\n",
    "awards_d = new_awards_d\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# deleting more duplicates\n",
    "del_set = set()\n",
    "for k in awards_d.keys():\n",
    "    k_lst = k.split(\" \")\n",
    "    for k2 in awards_d.keys():\n",
    "        k2_lst = k2.split(\" \")\n",
    "\n",
    "        if len(k_lst) >= len(k2_lst):\n",
    "            continue\n",
    "        elif k_lst == k2_lst[:len(k_lst)]:\n",
    "            del_set.add(k)\n",
    "for d in del_set:\n",
    "    del awards_d[d]\n",
    "\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# deleting awards that have \"in a\" but no \"Motion Picture / Television / Miniseries\"\n",
    "del_lst = []\n",
    "for k, v in awards_d.items():\n",
    "    if \"in a\" in k:\n",
    "        if not (\"Motion Picture\" in k or \"Television\" in k or \"Miniseries\" in k):\n",
    "            del_lst.append(k)\n",
    "for k in del_lst:\n",
    "    del awards_d[k]\n",
    "\n",
    "print(len(awards_d.keys()))\n",
    "\n",
    "# printing list of awards\n",
    "awards_lst = list(awards_d.keys())\n",
    "for a in awards_lst:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best dressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Golden Globes', 73),\n",
       " ('Anne Hathaway', 48),\n",
       " ('Tina Fey', 47),\n",
       " ('Jodie Foster', 41),\n",
       " ('Kate Hudson', 36),\n",
       " ('Jessica Alba', 32),\n",
       " ('Kerry Washington', 22),\n",
       " ('Jennifer Lawrence', 22),\n",
       " ('Jessica Chastain', 21),\n",
       " ('Jennifer Lopez', 21),\n",
       " ('Hugh Jackman', 19),\n",
       " ('Bradley Cooper', 17),\n",
       " ('Megan Fox', 17),\n",
       " ('Robert Downey', 16),\n",
       " ('George Clooney', 15),\n",
       " ('Taylor Swift', 14),\n",
       " ('Halle Berry', 12),\n",
       " ('Salma Hayek', 12),\n",
       " ('Ben Affleck', 12),\n",
       " ('Claire Danes', 11),\n",
       " ('Robert Pattinson', 10),\n",
       " ('Lea Michele', 10),\n",
       " ('Julianne Moore', 9),\n",
       " ('Kristen Wiig', 9),\n",
       " ('Julia Roberts', 9),\n",
       " ('Sofia Vergara', 8),\n",
       " ('The Golden', 8),\n",
       " ('Jennifer Garner', 8),\n",
       " ('Kristen Bell', 8),\n",
       " ('Birthday Boy', 8),\n",
       " ('Lucy Liu', 7),\n",
       " ('Amy Poehler', 7),\n",
       " ('Daniel Day', 7),\n",
       " ('Kevin Costner', 7),\n",
       " ('Hot Golden', 7),\n",
       " ('Amanda Seyfried', 5),\n",
       " ('Zuhair Murad', 5),\n",
       " ('Emily Blunt', 5),\n",
       " ('Eva Longoria', 5),\n",
       " ('Globes Anne', 5),\n",
       " ('Damian Lewis', 5),\n",
       " ('Denzel Washington', 4),\n",
       " ('Miranda Kerr', 4),\n",
       " ('Sarah Paulson', 4),\n",
       " ('Selena Gomez', 4),\n",
       " ('Catherine Zeta', 4),\n",
       " ('Rosario Dawson', 4),\n",
       " ('Annual Golden', 4),\n",
       " ('Bill Clinton', 4),\n",
       " ('Leonardo Di', 4),\n",
       " ('Jodi Foster', 4),\n",
       " ('Helen Mirren', 3),\n",
       " ('Sophia Vergara', 3),\n",
       " ('Michelle Dockery', 3),\n",
       " ('Daniel Craig', 3),\n",
       " ('Globes Adele', 3),\n",
       " ('Christoph Waltz', 3),\n",
       " ('Globes Red', 3),\n",
       " ('Sophia Vegara', 3),\n",
       " ('Richard Gere', 3),\n",
       " ('Jessica Lange', 3),\n",
       " ('Lena Dunham', 3),\n",
       " ('Les Miserables', 3),\n",
       " ('Jeremy Renner', 3),\n",
       " ('Best Original', 3),\n",
       " ('Kristin Wiig', 3),\n",
       " ('Ann Hathaway', 3),\n",
       " ('Helena Bonham', 3),\n",
       " ('Allison Williams', 3),\n",
       " ('Christian Bale', 3),\n",
       " ('Sally Field', 2),\n",
       " ('Vergara You', 2),\n",
       " ('Saint Laurent', 2),\n",
       " ('Jason Statham', 2),\n",
       " ('Nicole Kidman', 2),\n",
       " ('Tiny Fey', 2),\n",
       " ('Globes Kate', 2),\n",
       " ('Dennis Quaid', 2),\n",
       " ('Kerri Washington', 2),\n",
       " ('Meryl Streep', 2),\n",
       " ('Jon Hamm', 2),\n",
       " ('Selma Hayek', 2),\n",
       " ('Mel Gibson', 2),\n",
       " ('Paul Rudd', 2),\n",
       " ('Love Jessica', 2),\n",
       " ('Most Handsome', 2),\n",
       " ('Isla Fisher', 2),\n",
       " ('Maggie Smith', 2),\n",
       " ('Benedict Cumberbatch', 2),\n",
       " ('Best Dressed', 2),\n",
       " ('Globes Jessica', 2),\n",
       " ('Jamie Foxx', 2),\n",
       " ('Beautiful Speech', 2),\n",
       " ('Lucy Lu', 2),\n",
       " ('Debra Messing', 2),\n",
       " ('Don Cheadle', 2),\n",
       " ('Marion Cotillard', 2),\n",
       " ('Lea Michelle', 2),\n",
       " ('Jody Foster', 2),\n",
       " ('Va Va', 2),\n",
       " ('Best Motion', 2),\n",
       " ('Natalie Morales', 1),\n",
       " ('Miu Miu', 1),\n",
       " ('Loving Kerry', 1),\n",
       " ('Movado Gorgeous', 1),\n",
       " ('Watching Paranorman', 1),\n",
       " ('Rauch You', 1),\n",
       " ('Mr Pattinson', 1),\n",
       " ('Nicole Ritchie', 1),\n",
       " ('Kerr Sexy', 1),\n",
       " ('Insider Beautiful', 1),\n",
       " ('Hayden Panetierre', 1),\n",
       " ('Sofia Vagara', 1),\n",
       " ('Stunning Orlando', 1),\n",
       " ('Okay Leonardo', 1),\n",
       " ('Hathaway Boring', 1),\n",
       " ('Loving Naomi', 1),\n",
       " ('Leo Di', 1),\n",
       " ('Kelly Osbourne', 1),\n",
       " ('And Pauletta', 1),\n",
       " ('Omg Sara', 1),\n",
       " ('Stacy Keibler', 1),\n",
       " ('Is Matt', 1),\n",
       " ('Beautiful Dresses', 1),\n",
       " ('Sexy Jennifer', 1),\n",
       " ('Check Rob', 1),\n",
       " ('Sally Fields', 1),\n",
       " ('Sienna Miller', 1),\n",
       " ('Atelier Aubergine', 1),\n",
       " ('Im Sorry', 1),\n",
       " ('Lo Love', 1),\n",
       " ('Lo Looks', 1),\n",
       " ('Taylor Swiff', 1),\n",
       " ('Thank God', 1),\n",
       " ('Upright Must', 1),\n",
       " ('Designs\\nHayden', 1),\n",
       " ('Omg Tina', 1),\n",
       " ('Hello George', 1),\n",
       " ('Evaa Longoria', 1),\n",
       " ('Zooey Deschanel', 1),\n",
       " ('Damn Helen', 1),\n",
       " ('Leo Dicaprio', 1),\n",
       " ('Dayummm Tina', 1),\n",
       " ('Rachel Weisz', 1),\n",
       " ('Chiville Nicole', 1),\n",
       " ('Nominee Richard', 1),\n",
       " ('Beautiful Anne', 1),\n",
       " ('Gosh Jennifer', 1),\n",
       " ('Ahhhhhhhh Lea', 1),\n",
       " ('Omg Kate', 1),\n",
       " ('Arden Strong', 1),\n",
       " ('Best Dress', 1),\n",
       " ('Wow Kate', 1),\n",
       " ('Red Carpet', 1),\n",
       " ('Love Chistoph', 1),\n",
       " ('Beautiful Kerry', 1),\n",
       " ('Leonardo Decaprio', 1),\n",
       " ('And Connie', 1),\n",
       " ('Christopher Waltz', 1),\n",
       " ('Ok Miranda', 1),\n",
       " ('Miren Adele', 1),\n",
       " ('Listen Magnum', 1),\n",
       " ('Eva Longorias', 1),\n",
       " ('Red Carpets', 1),\n",
       " ('Globes Julianne', 1),\n",
       " ('Globes Tina', 1),\n",
       " ('Globes Debra', 1),\n",
       " ('Amy Phoeler', 1),\n",
       " ('Jullian Moore', 1),\n",
       " ('Love Julianne', 1),\n",
       " ('Julianne Morre', 1),\n",
       " ('Vanessa Hudgens', 1),\n",
       " ('Best Golden', 1),\n",
       " ('Leakes Getty', 1),\n",
       " ('More New', 1),\n",
       " ('Julianna Moore', 1),\n",
       " ('Hayden Panettier', 1),\n",
       " ('American Idol', 1),\n",
       " ('Globes George', 1),\n",
       " ('Nicole Richie', 1),\n",
       " ('Katherine Zeta', 1),\n",
       " ('Francesca Eastwood', 1),\n",
       " ('Hall Berry', 1),\n",
       " ('Globes Surprisingly', 1),\n",
       " ('Beautiful Helen', 1),\n",
       " ('Dev Patel', 1),\n",
       " ('Loving Cody', 1),\n",
       " ('Aida Takkla', 1),\n",
       " ('Yep Salma', 1),\n",
       " ('Omg Selma', 1),\n",
       " ('Selma Hyak', 1),\n",
       " ('Sexy Ginger', 1),\n",
       " ('Shaun Robinson', 1),\n",
       " ('Clair Danes', 1),\n",
       " ('Vivienne Westwood', 1),\n",
       " ('Morena Baccarin', 1),\n",
       " ('Globes Some', 1),\n",
       " ('El Redhead', 1),\n",
       " ('Saw Claire', 1),\n",
       " ('Selma Hayak', 1),\n",
       " ('Perry Is', 1),\n",
       " ('Tina Feys', 1),\n",
       " ('Globes Dress', 1),\n",
       " ('George Cloney', 1),\n",
       " ('Looks Smokin', 1),\n",
       " ('Globes Jennifer', 1),\n",
       " ('Sexy Ass', 1),\n",
       " ('Handsome Rob', 1),\n",
       " ('La Chica', 1),\n",
       " ('Lizette Luzcando', 1),\n",
       " ('John Williams', 1),\n",
       " ('Original Score', 1),\n",
       " ('Lo Ummm', 1),\n",
       " ('Naomi Watts', 1),\n",
       " ('Love Your', 1),\n",
       " ('Mychael Danna', 1),\n",
       " ('Adele Fantastic', 1),\n",
       " ('Omg Adele', 1),\n",
       " ('Only Adele', 1),\n",
       " ('Oh Kevin', 1),\n",
       " ('Jack Bauer', 1),\n",
       " ('Im Gunn', 1),\n",
       " ('Oh My', 1),\n",
       " ('These Golden', 1),\n",
       " ('Games Every', 1),\n",
       " ('Holy Jessica', 1),\n",
       " ('Wow Jessica', 1),\n",
       " ('Damn Johnny', 1),\n",
       " ('Holy Shit', 1),\n",
       " ('Kiefer Sutherland', 1),\n",
       " ('Could Jessica', 1),\n",
       " ('Gosh Kevin', 1),\n",
       " ('Ughhh Kevin', 1),\n",
       " ('Globes Our', 1),\n",
       " ('Neophytou Beautiful', 1),\n",
       " ('Mark Walburg', 1),\n",
       " ('Julianne Hough', 1),\n",
       " ('Zero Dark', 1),\n",
       " ('Jennifer Lo', 1),\n",
       " ('Emily Deschanel', 1),\n",
       " ('See Anjelica', 1),\n",
       " ('Kristen Wig', 1),\n",
       " ('Elie Saab', 1),\n",
       " ('Juliana Marguiles', 1),\n",
       " ('Will Ferrall', 1),\n",
       " ('Lo You', 1),\n",
       " ('Hollywood Dentists', 1),\n",
       " ('Tommy Lee', 1),\n",
       " ('Dustin Hoffman', 1),\n",
       " ('Oh Jennifer', 1),\n",
       " ('Chris Tucker', 1),\n",
       " ('Yay Jennifer', 1),\n",
       " ('Aww Jennifer', 1),\n",
       " ('Both Gorgeous', 1),\n",
       " ('Love Jennifer', 1),\n",
       " ('Jennifer Lawerence', 1),\n",
       " ('Ermagerd Jennifer', 1),\n",
       " ('Some Like', 1),\n",
       " ('Omfg Selena', 1),\n",
       " ('Gone With', 1),\n",
       " ('Globes Who', 1),\n",
       " ('Jenniefer Lawrence', 1),\n",
       " ('Will Ferrell', 1),\n",
       " ('Max Greenfield', 1),\n",
       " ('John Kransinski', 1),\n",
       " ('Gillispie She', 1),\n",
       " ('Danny Huston', 1),\n",
       " ('Megan Sexy', 1),\n",
       " ('Jonah Hill', 1),\n",
       " ('Hot Tin', 1),\n",
       " ('Go Anne', 1),\n",
       " ('Christmas Day', 1),\n",
       " ('Celebrity Anne', 1),\n",
       " ('My Original', 1),\n",
       " ('Globes Sally', 1),\n",
       " ('Globes Oh', 1),\n",
       " ('Wow Sally', 1),\n",
       " ('Verdi Anne', 1),\n",
       " ('Diet Pepsi', 1),\n",
       " ('Congratulations Anne', 1),\n",
       " ('Quentin Tarantino', 1),\n",
       " ('Django Unchained', 1),\n",
       " ('Salmon Fishing', 1),\n",
       " ('Moulin Rouge', 1),\n",
       " ('Robert Parttinson', 1),\n",
       " ('Love Red', 1),\n",
       " ('Was Megan', 1),\n",
       " ('Rob Pattison', 1),\n",
       " ('And Jennifer', 1),\n",
       " ('Michael Haneke', 1),\n",
       " ('Seacrest Has', 1),\n",
       " ('Sylvester Stallone', 1),\n",
       " ('Oh Nathan', 1),\n",
       " ('Oh Lea', 1),\n",
       " ('Charlie Sheen', 1),\n",
       " ('Could Claire', 1),\n",
       " ('Glen Close', 1),\n",
       " ('Fillion You', 1),\n",
       " ('Holy Lea', 1),\n",
       " ('Claire Daines', 1),\n",
       " ('Beautiful Lea', 1),\n",
       " ('First Look', 1),\n",
       " ('Eddie Redmayne', 1),\n",
       " ('Sacha Baron', 1),\n",
       " ('Los Angeles', 1),\n",
       " ('Evolution Played', 1),\n",
       " ('Orlando Bloom', 1),\n",
       " ('Hathaway Tribute', 1),\n",
       " ('Woah Liev', 1),\n",
       " ('Julia Louis', 1),\n",
       " ('Globes Tattoos', 1),\n",
       " ('Monique Lhuillier', 1),\n",
       " ('Leana Dunham', 1),\n",
       " ('Penelope Cruze', 1),\n",
       " ('Swifty Taylor', 1),\n",
       " ('Omg Robert', 1),\n",
       " ('Love Jodie', 1),\n",
       " ('Divorce Survival', 1),\n",
       " ('Okay So', 1),\n",
       " ('Damn Jodie', 1),\n",
       " ('Gorgeous Jodie', 1),\n",
       " ('Creys That', 1),\n",
       " ('To The', 1),\n",
       " ('Mark Wahlbergs', 1),\n",
       " ('For The', 1),\n",
       " ('Dear Jodie', 1),\n",
       " ('Young Hollywood', 1),\n",
       " ('Globes Beautiful', 1),\n",
       " ('Ooooh Halle', 1),\n",
       " ('Halle Barry', 1),\n",
       " ('Globes Halle', 1),\n",
       " ('Yeah Ben', 1),\n",
       " ('Billy Bob', 1),\n",
       " ('Lens Dunham', 1),\n",
       " ('Yes Jodie', 1),\n",
       " ('Bruce Willis', 1),\n",
       " ('Celebrity Halle', 1),\n",
       " ('Celebrity Ben', 1),\n",
       " ('Globes Jodie', 1),\n",
       " ('Press\\nMark', 1),\n",
       " ('Ahhh Christian', 1),\n",
       " ('Jack Black', 1),\n",
       " ('So Many', 1),\n",
       " ('Hi Hugh', 1),\n",
       " ('Les Mis', 1),\n",
       " ('Globes Hugh', 1),\n",
       " ('These Target', 1),\n",
       " ('Hair For', 1),\n",
       " ('Solis Your', 1),\n",
       " ('Jesscia Chastain', 1),\n",
       " ('Hot Or', 1),\n",
       " ('Aww Hugh', 1),\n",
       " ('Loooooooove Hugh', 1),\n",
       " ('Heidi Klum', 1),\n",
       " ('Miserable Such', 1),\n",
       " ('Abu Nazir', 1),\n",
       " ('Hot British', 1),\n",
       " ('Hot Ginger', 1),\n",
       " ('More Lena', 1),\n",
       " ('Oh George', 1),\n",
       " ('Jodi Fosters', 1),\n",
       " ('Goooo Daniel', 1),\n",
       " ('Especially Amy', 1),\n",
       " ('Has Richard', 1),\n",
       " ('Woo Daniel', 1),\n",
       " ('Julie Roberts', 1),\n",
       " ('Did Julia', 1),\n",
       " ('Could Julia', 1),\n",
       " ('Damn Julia', 1),\n",
       " ('Loved Tina', 1),\n",
       " ('Not Best', 1),\n",
       " ('Thank You', 1),\n",
       " ('Adele Adele', 1),\n",
       " ('Absurdly Gorgeous', 1),\n",
       " ('Award Show', 1),\n",
       " ('Wet Hot', 1),\n",
       " ('Moore Gone', 1),\n",
       " ('Golden Globe', 1),\n",
       " ('Holy Moly', 1),\n",
       " ('Oh Leonardo', 1),\n",
       " ('Was Julia', 1),\n",
       " ('Swift Taylor', 1),\n",
       " ('News Taylor', 1)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_best = []\n",
    "for tw in data_no_rt:\n",
    "    text = tw[\"text\"]\n",
    "\n",
    "    if re.search(\"beautiful|gorgeous|fabulous|sexy|dashing|handsome|\\shot\\s|impeccable\", text.lower()):\n",
    "        poss_person = re.search(\"[A-Z][a-z]+\\s[A-Z][a-z]+\\s\", text)\n",
    "        if poss_person:\n",
    "            has_best.append(text[poss_person.start():poss_person.end()].strip())\n",
    "\n",
    "g_dress_tw = Counter(has_best)\n",
    "g_dress_tw.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse Dressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claire Danes\n"
     ]
    }
   ],
   "source": [
    "has_best = []\n",
    "for tw in data_no_rt:\n",
    "    text = tw[\"text\"]\n",
    "\n",
    "    if re.search(\"hideous|ridiculous|ugly|\\sbland\\s|looks.+\\sbad|bad\\s.+looks\", text.lower()):\n",
    "        poss_person = re.search(\"[A-Z][a-z]+\\s[A-Z][a-z]+\\s\", text)\n",
    "        if poss_person:\n",
    "            has_best.append(text[poss_person.start():poss_person.end()].strip())\n",
    "\n",
    "w_dress_tw = Counter(has_best)\n",
    "worse_dressed = w_dress_tw.most_common()[1][0]\n",
    "print(worse_dressed)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
